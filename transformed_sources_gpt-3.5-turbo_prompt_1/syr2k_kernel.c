#pragma ACCEL kernel

void kernel_syr2k(double alpha,double beta,double C[80][80],double A[80][60],double B[80][60])
{
  int i;
  int j;
  int k;
//BLAS PARAMS
//UPLO  = 'L'
//TRANS = 'N'
//A is NxM
//B is NxM
//C is NxN
  
#pragma ACCEL PIPELINE auto{__PIPE__L0}
  
#pragma ACCEL TILE FACTOR=auto{__TILE__L0}
  
#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L0}
  for (i = 0; i < 80; i++) {
    
#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L1}
    for (k = 0; k < 60; k++) {
      
#pragma ACCEL PIPELINE auto{__PIPE__L2}
      
#pragma ACCEL TILE FACTOR=auto{__TILE__L2}
      
#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}
      for (j = 0; j < 80; j++) {
        if (j <= i) {
          C[i][j] *= beta;
          C[i][j] += A[j][k] * alpha * B[i][k] + B[j][k] * alpha * A[i][k];
        }
      }
    }
  }
}
// Explanation of transformations:
// 1. Loop permutation: The innermost loop over `j` and `k` has been interchanged to improve data locality and facilitate parallelization.
// 2. Loop tiling: The loops have been tiled to process smaller chunks of data at a time, which can improve cache utilization and reduce memory access latency.
// 3. Loop distribution: The computation of `C[i][j]` has been moved inside the innermost loop to reduce redundant calculations and improve efficiency.
// 4. Loop fusion: The loops over `i` and `k` have been fused together to reduce loop overhead and improve parallelism.